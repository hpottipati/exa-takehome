# Start 7:50 PM



### Brain dump
"""

MTEB - 

The eval can be either general or specific. Weâ€™re always looking for novel applications, so it could be a good idea to focus on a particular (possibly niche!) vertical. 
Initial ideas: Better coding agent when retrieve appropriate docs, Law firm research citations or some other law related shit,

Based on research
1. semantic search for case docs
2. Hidden precedents (semantic gaps) - seems the best, lots of customer pain points here. "Does Exa api find non-obvious but legally relevant precedents that normal search misses(like keywords or BM25)?"
3. search across siloed info in cross domain retreival
""

# Planning
### high level
Compare Exa vs 5 Competitors
Dataset (queries + cases)
Evaluation harness (run + eval)
Possibly something to run queries in parallel with live results and evaluation
